opt:
  net_arch: cifar_toy
  lr: 0.001
  wd: 0.0005
  dataset: cifar10
  data_path: ~/awesomePhD/Datasets/
  batch_size: 16
  seed: 2020

trainer_opt:
  gpus: 0
  max_epochs: 5
  precision: 32
  min_nb_epochs: 1
  log_save_interval: 5
  num_sanity_val_steps: 1
  early_stop_callback: False
  train_percent_check: 0.1 
  val_percent_check: 0.1
#  distributed_backend: ddp

logging_opt:
  save_dir: ./logs/
  name: examples
  version: version_cifar10_cpu

ckpt_opt:
  save_top_k: -1
  period: 5